{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "mount_file_id": "1EeBfbjr985bvmiTmrtj8L2nbU1cggM8e",
      "authorship_tag": "ABX9TyPRGgpUl93a5H4vdoowDexD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuzhouLin/current_proj/blob/newbranch/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hJ-x1n0wteC",
        "outputId": "1fe4025e-fb46-4d34-ddb8-603437120fc0"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAcgHay7173T",
        "outputId": "22d18e2b-ecd1-49ed-b863-857518d43592"
      },
      "source": [
        "%cd drive/My\\ Drive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5I366k2CbT",
        "outputId": "1193d548-fd9f-413a-f7df-19558606225e"
      },
      "source": [
        "!git clone https://github.com/YuzhouLin/current_proj.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'current_proj'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 118 (delta 33), reused 114 (delta 29), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (118/118), 4.35 MiB | 12.66 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do-kZnPiSjqc"
      },
      "source": [
        "import numpy as np\r\n",
        "import scipy.special as sc\r\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4CybSTfcnG6",
        "outputId": "41ea937d-d2fc-4bbb-b481-981b8ef4d72e"
      },
      "source": [
        "a = {\r\n",
        "    'a':1,\r\n",
        "    'b':2,\r\n",
        "    'c':3,\r\n",
        "    'd':4\r\n",
        "}\r\n",
        "\r\n",
        "b= [\"c\",\"d\"]\r\n",
        "\r\n",
        "#out = {item:a.get(item) for item in b}\r\n",
        "\r\n",
        "out = {'b':a.get('b')}\r\n",
        "\r\n",
        "out.update({item:a.get(item) for item in b})\r\n",
        "\r\n",
        "#out[item] = a.get(item) for item in b\r\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'b': 2, 'c': 3, 'd': 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amL3m0QgSrQc",
        "outputId": "fa23c53e-5ceb-4074-cfb2-980a896650d6"
      },
      "source": [
        "###  Calculate Vacuity and dissonance \r\n",
        "\r\n",
        "def Bal(a,b):\r\n",
        "    if a*b !=0:\r\n",
        "        output = 1-abs(a-b)/(a+b)\r\n",
        "    else:\r\n",
        "        output = 0\r\n",
        "    return output        \r\n",
        "\r\n",
        "#evidence = np.array([99]*12)\r\n",
        "evidence = np.array([4,9,0])\r\n",
        "alpha = evidence + 1\r\n",
        "prob_SL = alpha / np.sum(alpha)\r\n",
        "class_num = len(evidence)\r\n",
        "total_evidence = np.sum(alpha)\r\n",
        "\r\n",
        "u_va = class_num / total_evidence\r\n",
        "\r\n",
        "print('The vacuity is: %.2f' %(u_va))\r\n",
        "\r\n",
        "belief = evidence/total_evidence\r\n",
        "belief = belief.tolist()\r\n",
        "u_dis = 0.0\r\n",
        "for index_k,k in enumerate(belief):\r\n",
        "    temp0 = 0.0\r\n",
        "    temp1 = 0.0\r\n",
        "    for index_j,j in enumerate(belief):\r\n",
        "        if index_j!=index_k:\r\n",
        "            temp0 += j*Bal(k,j)\r\n",
        "            temp1 += j\r\n",
        "    if temp1!=0:\r\n",
        "        u_dis += k*temp0/temp1\r\n",
        "print('The dissonance is: %.2f' %(u_dis))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The vacuity is: 0.19\n",
            "The dissonance is: 0.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IneNE9R9tGD",
        "outputId": "1735d2b5-259d-4aeb-dc52-5de0bb2233e1"
      },
      "source": [
        "import torch\r\n",
        "#alpha = torch.ones([1, 12], dtype=torch.float32)\r\n",
        "belief = torch.tensor([[0.3,0.3,0.0],[0.1,0.1,0.1]], dtype=torch.float32,requires_grad=True)\r\n",
        "k_class = 3\r\n",
        "\r\n",
        "'''\r\n",
        "def Bal(a,b,batch_n):\r\n",
        "    output = torch.where(a*b>0,1.0-torch.abs(a-b)/(a+b),0)\r\n",
        "    if a*b !=0:\r\n",
        "        output = 1.0-torch.abs(a-b)/(a+b)\r\n",
        "    else:\r\n",
        "        output = torch.Tensor.zeros(batch_n,1)\r\n",
        "    return output\r\n",
        "'''\r\n",
        "\r\n",
        "batch_n = belief.size()[0]\r\n",
        "u_dis = torch.zeros(batch_n,1)\r\n",
        "for index_k in range(k_class):\r\n",
        "    temp0 = torch.zeros(batch_n,1)\r\n",
        "    temp1 = torch.zeros(batch_n,1)\r\n",
        "    for index_j in range(k_class):\r\n",
        "        if index_j!=index_k:\r\n",
        "            k = belief[:,index_k].reshape(batch_n ,1)\r\n",
        "            j = belief[:,index_j].reshape(batch_n ,1)\r\n",
        "            temp0 += j*(1.0-torch.abs(k-j)/(k+j+1e-8))\r\n",
        "            #torch.where(k*j>0.0,1.0-torch.abs(k-j)/(k+j),torch.zeros(batch_n,1))\r\n",
        "            temp1 += j\r\n",
        "    u_dis += k*temp0/(temp1+1e-8)\r\n",
        "\r\n",
        "u_dis.sum().backward()\r\n",
        "print(belief.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0000,  1.0000, -2.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw-jy4FdESyv",
        "outputId": "8d2259bd-693e-4aa7-ed18-efb9d4763be8"
      },
      "source": [
        "import numpy as np\r\n",
        "a = np.array([[1.0],[2.0],[3.0]])\r\n",
        "b = np.array([[2.0],[1.0],[10.0]])\r\n",
        "c = np.concatenate((a,b),axis=1)\r\n",
        "print(np.shape(a))\r\n",
        "d = np.max(c,axis=1,keepdims=True)\r\n",
        "print(np.shape(d))\r\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 1)\n",
            "(3, 1)\n",
            "[[ 2.]\n",
            " [ 2.]\n",
            " [10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM2AHjq36bkw",
        "outputId": "29613d98-11a3-4c0c-8841-50208d177b80"
      },
      "source": [
        "import torch\r\n",
        "x_data = [1.0, 2.0, 3.0]\r\n",
        "y_data = [2.0, 4.0, 6.0]\r\n",
        " \r\n",
        "w = torch.Tensor([1.0]) # w的初值为1.0\r\n",
        "w.requires_grad = True # 需要计算梯度\r\n",
        "\r\n",
        "\r\n",
        "#print(w.grad.data.type())\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def forward(x):\r\n",
        "    return x*w  # w是一个Tensor\r\n",
        " \r\n",
        " \r\n",
        "def loss(x, y):\r\n",
        "    y_pred = forward(x)\r\n",
        "    return (y_pred - y)**2\r\n",
        " \r\n",
        "print(\"predict (before training)\", 4, forward(4).item())\r\n",
        " \r\n",
        "for epoch in range(10):\r\n",
        "    for x, y in zip(x_data, y_data):\r\n",
        "        l =loss(x,y) # l是一个张量，tensor主要是在建立计算图 forward, compute the loss\r\n",
        "        l.backward() #  backward,compute grad for Tensor whose requires_grad set to True\r\n",
        "\r\n",
        "        print(w.data.type())\r\n",
        "        print(w.grad.data.type())\r\n",
        "        break\r\n",
        "        print('\\tgrad:', x, y, w.grad.item())\r\n",
        "        w.data = w.data - 0.01 * w.grad.data   # 权重更新时，需要用到标量，注意grad也是一个tensor\r\n",
        " \r\n",
        "        w.grad.data.zero_() # after update, remember set the grad to zero\r\n",
        " \r\n",
        "    print('progress:', epoch, l.item()) # 取出loss使用l.item，不要直接使用l（l是tensor会构建计算图）\r\n",
        " \r\n",
        "print(\"predict (after training)\", 4, forward(4).item())\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (before training) 4 4.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 0 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 1 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 2 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 3 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 4 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 5 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 6 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 7 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 8 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 9 1.0\n",
            "predict (after training) 4 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HElo7ysrPx2B",
        "outputId": "e35d615e-becf-4338-c55c-891bd340c820"
      },
      "source": [
        "evidence = np.array([19]*12)\r\n",
        "print(evidence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19 19 19 19 19 19 19 19 19 19 19 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6saVw18emyO"
      },
      "source": [
        "### Loss function\r\n",
        "def loss_cal(para):\r\n",
        "    y_label = np.array([1,0,0,0,0,0,0,0,0,0,0,0])\r\n",
        "    \r\n",
        "    # parameters: alphas\r\n",
        "    S = np.sum(para)\r\n",
        "    pred = para/S\r\n",
        "    pred_err = np.sum(np.square(pred-y_label))\r\n",
        "\r\n",
        "    pred_var = np.sum(pred*(1-pred)/(S+1))\r\n",
        "    #pred_var = np.sum(pred*(1-pred))\r\n",
        "    return pred_err,pred_var\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0epVWITNvdM7"
      },
      "source": [
        "def kl_divergence(para,n_class=3):\r\n",
        "    beta = np.ones()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPsW7dAUf0D-",
        "outputId": "1a3dca45-f736-4494-9e99-ec506631e595"
      },
      "source": [
        "alphas = np.array([10,12,10,10,10,10,10,10,10,10,10,10])\r\n",
        "pred_err,pred_var = loss_cal(alphas)\r\n",
        "print(pred_err,pred_var,pred_err+pred_var)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9196452566514377 0.007450571683894748 0.9270958283353324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfzpqLR7grAT",
        "outputId": "f00095a4-e4ae-4ef9-ae9f-8476a5ef1bc0"
      },
      "source": [
        "prob = np.array([0,0.5,0])\r\n",
        "print(mse_loss(prob))\r\n",
        "prob = np.array([0,0.4,0.3])\r\n",
        "print(mse_loss(prob))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.25\n",
            "1.2500000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84t6pqoyVro8",
        "outputId": "40ec5b89-59f7-4f8b-f457-7d5416b30121"
      },
      "source": [
        "alphas = np.array([1,10,8])\r\n",
        "alphas = (alphas-1)*(1-np.array([1,0,0]))+1\r\n",
        "print(alphas)\r\n",
        "beta = np.ones(3)\r\n",
        "#beta = np.array([8,8,8])\r\n",
        "S_alpha = np.sum(alphas)\r\n",
        "print(S_alpha)\r\n",
        "S_beta = np.sum(beta)\r\n",
        "print(S_beta)\r\n",
        "lnB = sc.gammaln(S_alpha) - np.sum(sc.gammaln(alphas))\r\n",
        "print(lnB)\r\n",
        "lnB_uni = np.sum(sc.gammaln(beta)) - sc.gammaln(S_beta)\r\n",
        "print(lnB_uni)\r\n",
        "dg0 = sc.digamma(S_alpha)\r\n",
        "dg1 = sc.digamma(alphas)\r\n",
        "kl = np.sum((alphas-beta)*(dg1-dg0))+lnB+lnB_uni\r\n",
        "print(kl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 10  8]\n",
            "19\n",
            "3.0\n",
            "15.068456366886167\n",
            "-0.6931471805599453\n",
            "2.0642942208994857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tjiyG4l0Zm-",
        "outputId": "c507a773-6709-469c-a7f8-2199f839cd43"
      },
      "source": [
        "y = np.array([1,0,0])\r\n",
        "kl_alpha = (alphas - 1) * (1 - y) + 1\r\n",
        "print(kl_alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oYcsz3-y_Uv",
        "outputId": "156a9b28-0552-4532-c915-6fbaad1a150f"
      },
      "source": [
        "import torch\r\n",
        "#alpha = torch.ones([1, 12], dtype=torch.float32)\r\n",
        "alpha = torch.tensor([[1,20,1,1,18,1,1,18,1,1,1,1]], dtype=torch.float32)\r\n",
        "beta = torch.ones([1, 12], dtype=torch.float32)\r\n",
        "S_alpha = torch.sum(alpha, dim=1, keepdim=True)\r\n",
        "print(S_alpha)\r\n",
        "S_beta = torch.sum(beta, dim=1, keepdim=True)\r\n",
        "print(S_beta)\r\n",
        "lnB = torch.lgamma(S_alpha) - \\\r\n",
        "    torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\r\n",
        "print(lnB)\r\n",
        "lnB_uni = torch.sum(torch.lgamma(beta), dim=1,\r\n",
        "                    keepdim=True) - torch.lgamma(S_beta)\r\n",
        "print(lnB_uni)\r\n",
        "dg0 = torch.digamma(S_alpha)\r\n",
        "dg1 = torch.digamma(alpha)\r\n",
        "\r\n",
        "kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1,\r\n",
        "                keepdim=True) + lnB + lnB_uni\r\n",
        "\r\n",
        "print(kl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[65.]])\n",
            "tensor([[12.]])\n",
            "tensor([[98.8182]])\n",
            "tensor([[-17.5023]])\n",
            "tensor([[14.2415]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZtH_l4NnTW4"
      },
      "source": [
        "y = torch.tensor([[1,0,0,0,0,0,0,0,0,0,0,0]], dtype=torch.float32)\r\n",
        "#print(1-torch.sum(alpha*y,dim=1,keepdim=True)/torch.sum(alpha, dim=1, keepdim=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "IVFxqAT5vukC",
        "outputId": "580f9f2d-eecc-46e2-f64c-8a885a388b37"
      },
      "source": [
        "y2 = torch.tensor([[2,3,0,0,0,0,0,0,0,0,0,0]], dtype=torch.float32)\r\n",
        "#print(torch.dot(y2,y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c6e45867a60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IjpBH4ZwN0m",
        "outputId": "fb035918-c4d0-4e5b-9a0f-e23f08d026db"
      },
      "source": [
        "y3 = torch.tensor([[2],[3],[4]])\r\n",
        "print(y2.reshape(3,4)/y3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 1.5000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM9DCUVEuPI6",
        "outputId": "e737ce19-cc2e-4333-f37e-9cd26734d8ed"
      },
      "source": [
        "value = 5\r\n",
        "temp = y[y!=torch.max(y)]\r\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJfj7eGWgPiP",
        "outputId": "d2ce5b3d-f4fa-40cb-8cc7-214c97e71c53"
      },
      "source": [
        "a = [1,2,3]\r\n",
        "a[0],a[1],a[2] = a[2],a[1],a[0]\r\n",
        "print(a)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "RWt3zrocqswV",
        "outputId": "5b077580-83a2-4eff-b921-510dcaec360d"
      },
      "source": [
        "import torch\r\n",
        "import matplotlib.pyplot as plt  \r\n",
        "a = torch.linspace(0, 1, 10, requires_grad=True)\r\n",
        "b = torch.tensor([0.5], requires_grad=True)\r\n",
        "loss = torch.abs(a-b)/(a+b+1e-8)\r\n",
        "loss.backward() \r\n",
        "plt.plot(a.detach().numpy(), a.grad.detach().numpy(), label='grad')\r\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000], requires_grad=True)\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d54679741c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Jkiu2ngT0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06a99d0-6fdb-46bc-bd9c-b08d207323e7"
      },
      "source": [
        "import torch\r\n",
        "a = torch.tensor([0.3],requires_grad=True)\r\n",
        "b = torch.tensor([0.2],requires_grad=True)\r\n",
        "#loss = torch.where(a*b>0,torch.abs(a-b)/(a+b+1e-8), torch.abs(a-b)/(a+b+1e-8))\r\n",
        "#loss = torch.where(a*b>0,torch.abs(a-b)/(a+b+1e-8), torch.zeros(1,1))\r\n",
        "loss = 1-torch.abs(a-b)/(a+b+1e-8)\r\n",
        "#loss = torch.where(torch.abs(a-b)<=1e-3, 0.5*(a-b)**2/(a+b+1e-8), (1e-3*torch.abs(a-b)-0.5*1e-3**2)/(a+b+1e-8))\r\n",
        "loss.backward()\r\n",
        "print(a.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.6000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pCzX9Xt3dde",
        "outputId": "216ffc52-1e5a-4a11-d36d-0363647876e4"
      },
      "source": [
        "a = torch.tensor([[10.,2.0,3.0]],requires_grad=True)\r\n",
        "b = torch.sum(a,dim=1, keepdim=True)\r\n",
        "loss = torch.log(b)\r\n",
        "loss.backward()\r\n",
        "print(a.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0667, 0.0667, 0.0667]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IidNgRkr5jdP",
        "outputId": "72f0eb27-8fa8-4d8c-b42d-4518c3bf0bad"
      },
      "source": [
        "a = torch.tensor([0.4],requires_grad=True)\r\n",
        "loss = (a-0.5)/(a+0.5)\r\n",
        "loss.backward()\r\n",
        "print(a.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.2346])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbVMxpXcAQr7",
        "outputId": "89c5d4eb-f8e2-4e42-b564-54d39da51df4"
      },
      "source": [
        "index = y>0\r\n",
        "y2 = torch.tensor([[2,0.5,0,0,0,0,0,0,0,0,0,0]])\r\n",
        "print(index*y+y2*(~index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SE1vCDJ0oayL",
        "outputId": "f0799a40-70be-457b-dd63-9fef36cb550c"
      },
      "source": [
        "outputs = torch.tensor([[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0,0],[1,0.9,0.8,0.7,0.6,5.5,0.4,0.3,0.2,0.1,0,0]], dtype=torch.float32)\r\n",
        "print(outputs.size())\r\n",
        "_, preds = torch.max(outputs, 1)\r\n",
        "print(preds)\r\n",
        "\r\n",
        "print(torch.eq(preds, preds))\r\n",
        "\r\n",
        "mean = torch\r\n",
        "var =  torch.tensor([[0.1,0.3]], dtype=torch.float32)\r\n",
        "index = var > 0.5\r\n",
        "print(index)\r\n",
        "index = mean + var > 0.5\r\n",
        "print(index)\r\n",
        "print(mean + var)\r\n",
        "_, preds = torch.max(outputs, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12])\n",
            "tensor([0, 5])\n",
            "tensor([True, True])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvar =  torch.tensor([[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,1,0.1,0.1,0.1]], dtype=torch.float32)\\nindex = var > 0.5\\nprint(index)\\nindex = mean + var > 0.5\\nprint(index)\\nprint(mean + var)\\n\\n_, preds = torch.max(outputs, 1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1kVmdFoAjrS"
      },
      "source": [
        "y = torch.tensor([[1,0,0],[1,0,0],[1,0,0]], dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woXLvNfiBfwM"
      },
      "source": [
        "def get_device():\r\n",
        "    use_cuda = torch.cuda.is_available()\r\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\r\n",
        "    return device\r\n",
        "\r\n",
        "def loglikelihood_loss(y, alpha, device=None):\r\n",
        "    if not device:\r\n",
        "        device = get_device()\r\n",
        "    y = y.to(device)\r\n",
        "    alpha = alpha.to(device)\r\n",
        "    S = torch.sum(alpha, dim=1, keepdim=True)\r\n",
        "    loglikelihood_err = torch.sum(\r\n",
        "        (y - (alpha / S)) ** 2, dim=1, keepdim=True)\r\n",
        "    loglikelihood_var = torch.sum(\r\n",
        "        alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\r\n",
        "    #loglikelihood = loglikelihood_err + loglikelihood_var\r\n",
        "    return loglikelihood_err,loglikelihood_var\r\n",
        "\r\n",
        "def kl_divergence(alpha, num_classes, device=None):\r\n",
        "    if not device:\r\n",
        "        device = get_device()\r\n",
        "    beta = torch.ones([1, num_classes], dtype=torch.float32, device=device)\r\n",
        "    S_alpha = torch.sum(alpha, dim=1, keepdim=True)\r\n",
        "    S_beta = torch.sum(beta, dim=1, keepdim=True)\r\n",
        "    lnB = torch.lgamma(S_alpha) - \\\r\n",
        "        torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\r\n",
        "    lnB_uni = torch.sum(torch.lgamma(beta), dim=1,\r\n",
        "                        keepdim=True) - torch.lgamma(S_beta)\r\n",
        "\r\n",
        "    dg0 = torch.digamma(S_alpha)\r\n",
        "    dg1 = torch.digamma(alpha)\r\n",
        "\r\n",
        "    kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1,\r\n",
        "                   keepdim=True) + lnB + lnB_uni\r\n",
        "    return kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkXDWFpEAwYp",
        "outputId": "20f567c5-0d64-415d-d50a-e7283a6be3a0"
      },
      "source": [
        "import torch.nn.functional as F\r\n",
        "y = torch.tensor([[1,0,-1],[0,1,0],[0,0,1]]*3, dtype=torch.float32)\r\n",
        "print(F.softmax(y,dim=1))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6652, 0.2447, 0.0900],\n",
            "        [0.2119, 0.5761, 0.2119],\n",
            "        [0.2119, 0.2119, 0.5761],\n",
            "        [0.6652, 0.2447, 0.0900],\n",
            "        [0.2119, 0.5761, 0.2119],\n",
            "        [0.2119, 0.2119, 0.5761],\n",
            "        [0.6652, 0.2447, 0.0900],\n",
            "        [0.2119, 0.5761, 0.2119],\n",
            "        [0.2119, 0.2119, 0.5761]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqOWB94hkEV5",
        "outputId": "3a8c5572-5f82-4937-8526-3f7ed437c21b"
      },
      "source": [
        "y2 = torch.tensor([1,2,3,4,5,6,7,8,9]).reshape(9,1)\r\n",
        "print(y*y2)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 2., 0.],\n",
            "        [0., 0., 3.],\n",
            "        [4., 0., 0.],\n",
            "        [0., 5., 0.],\n",
            "        [0., 0., 6.],\n",
            "        [7., 0., 0.],\n",
            "        [0., 8., 0.],\n",
            "        [0., 0., 9.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2mltul3BgTu"
      },
      "source": [
        "temp = [[3,1,1], # ideal\r\n",
        "        [1,2,1], # ideal\r\n",
        "        [1,1,3], # ideal\r\n",
        "        [10,8,1], # practial\r\n",
        "        [8,10,1], # practical \r\n",
        "        [1,2,3], # practical\r\n",
        "        [1,4,1], # wrong \r\n",
        "        [3,1,1], # wrong \r\n",
        "        [1,2,1]  # wrong \r\n",
        "        ]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZp2upKPEI9B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "89ef4b7e-6955-416d-9db8-905462f6fdd0"
      },
      "source": [
        "alpha = torch.tensor(temp, dtype=torch.float32)\r\n",
        "#A_err,A_var = loglikelihood_loss(y, alpha)\r\n",
        "kl_alpha = (alpha - 1) * (1 - y) + 1\r\n",
        "kl_div = kl_divergence(kl_alpha, 3)\r\n",
        "#loss = torch.mean(A+kl_div)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f95da6c674a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA_err\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloglikelihood_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkl_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkl_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#loss = torch.mean(A+kl_div)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3ecca3a6c9cb>\u001b[0m in \u001b[0;36mloglikelihood_loss\u001b[0;34m(y, alpha, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     loglikelihood_err = torch.sum(\n\u001b[0;32m---> 13\u001b[0;31m         (y - (alpha / S)) ** 2, dim=1, keepdim=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m     loglikelihood_var = torch.sum(\n\u001b[1;32m     15\u001b[0m         alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (9) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyj1VYgsE0d0",
        "outputId": "ceaa1952-5461-49de-c22d-b9bf315fe83b"
      },
      "source": [
        "print(A_err)\r\n",
        "print(kl_div)\r\n",
        "print(kl_div+A_err)\r\n",
        "print(torch.mean(A_err+kl_div))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2400],\n",
            "        [0.3750],\n",
            "        [0.2400],\n",
            "        [0.3889],\n",
            "        [0.2857],\n",
            "        [0.3889],\n",
            "        [1.1667],\n",
            "        [1.0400],\n",
            "        [0.8750]])\n",
            "tensor([[0.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [0.2653],\n",
            "        [0.2653],\n",
            "        [0.2653],\n",
            "        [0.9526],\n",
            "        [0.6251],\n",
            "        [0.2653]])\n",
            "tensor([[0.2400],\n",
            "        [0.3750],\n",
            "        [0.2400],\n",
            "        [0.6542],\n",
            "        [0.5510],\n",
            "        [0.6542],\n",
            "        [2.1193],\n",
            "        [1.6651],\n",
            "        [1.1403]])\n",
            "tensor(0.8488)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iukn8zjtFYVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4646f165-560c-4bac-a206-677402f4a638"
      },
      "source": [
        "y = torch.tensor([[1.0,2.0],[2.0,0.5],[0.2,3]], dtype=torch.float32)\r\n",
        "label = torch.tensor([1,0,0])\r\n",
        "_,p = torch.max(y,1)\r\n",
        "print(torch.where(label==p,1,-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1,  1, -1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7i_OM9LWSuc",
        "outputId": "38df0575-b9f0-4f5f-c08e-e6e5bf54ff45"
      },
      "source": [
        "y[:,-1].reshape(3,1).size()\r\n",
        "#print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4iy64yAZQBM",
        "outputId": "1eb402a5-c123-4cdc-97c2-c6ab07a30d18"
      },
      "source": [
        "y[:,:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000],\n",
              "        [2.0000],\n",
              "        [0.2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}