{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "mount_file_id": "1EeBfbjr985bvmiTmrtj8L2nbU1cggM8e",
      "authorship_tag": "ABX9TyNU0jmQZlDk2OxkY9YcUYw9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuzhouLin/current_proj/blob/feature-20210203-devtest/plot_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hJ-x1n0wteC",
        "outputId": "5b22bf2f-912b-4b6d-9641-2ad14192db2d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Y9Luai6t02",
        "outputId": "513892e5-7107-456f-8a83-947c3ec9cf78"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/current_proj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQSeah0wQNgo",
        "outputId": "41f0943f-4134-4496-c3d3-95722a8b788b"
      },
      "source": [
        "%cd drive/MyDrive/current\\_proj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/current_proj'\n",
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5I366k2CbT",
        "outputId": "1bd7dc06-5e38-47d1-fb5f-f71924fa7203"
      },
      "source": [
        "!git status"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "On branch googlecolab\n",
            "Your branch is ahead of 'origin/newbranch' by 5 commits.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvMMCcBpbvCh"
      },
      "source": [
        "!git branch -m googlecolab"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CapunyaDU3wU",
        "outputId": "705e6bd8-9bb3-4791-c46d-eb3c3c839c44"
      },
      "source": [
        "!git pull origin feature-20210203-devtest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From https://github.com/YuzhouLin/current_proj\n",
            " * branch            feature-20210203-devtest -> FETCH_HEAD\n",
            "Updating 330696e..7c124b3\n",
            "Checking out files: 100% (329/329), done.\n",
            "Fast-forward\n",
            " .gitignore                               |    1 \u001b[31m-\u001b[m\n",
            " src/create_folds.py => __init__.py       |    0\n",
            " data/NinaproDB5/raw/sb10_trial1.pkl      |  Bin \u001b[31m0\u001b[m -> \u001b[32m5876546\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb10_trial2.pkl      |  Bin \u001b[31m0\u001b[m -> \u001b[32m6651580\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb10_trial3.pkl      |  Bin \u001b[31m0\u001b[m -> \u001b[32m6697752\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb10_trial4.pkl      |  Bin \u001b[31m0\u001b[m -> \u001b[32m6562530\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb10_trial5.pkl      |  Bin \u001b[31m0\u001b[m -> \u001b[32m6120598\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb10_trial6.pkl      |  Bin \u001b[31m0\u001b[m -> \u001b[32m6110704\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb1_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5233436\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb1_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4860762\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb1_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5150986\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb1_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5236734\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb1_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5101516\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb1_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4893742\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb2_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6737328\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb2_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6417418\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb2_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6219538\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb2_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6605408\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb2_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6255816\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb2_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6341564\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb3_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5322482\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb3_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4840974\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb3_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4620008\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb3_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4827782\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb3_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4517770\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb3_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5312588\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb4_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5909526\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb4_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5919420\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb4_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5982082\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb4_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6051340\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb4_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5850162\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb4_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m7202346\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb5_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m4807994\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb5_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5121304\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb5_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5150986\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb5_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5085026\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb5_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5266416\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb5_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5121304\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb6_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6935208\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb6_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6770308\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb6_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6654878\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb6_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6295392\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb6_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6170068\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb6_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6714242\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb7_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6133790\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb7_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m6130492\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb7_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5246628\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb7_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5836970\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb7_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5477488\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb7_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5170774\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb8_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5850162\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb8_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5101516\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb8_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5530256\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb8_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5510468\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb8_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5447806\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb8_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5094920\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb9_trial1.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5289502\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb9_trial2.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5817182\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb9_trial3.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5282906\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb9_trial4.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5160880\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb9_trial5.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5048748\u001b[m bytes\n",
            " data/NinaproDB5/raw/sb9_trial6.pkl       |  Bin \u001b[31m0\u001b[m -> \u001b[32m5698454\u001b[m bytes\n",
            " draft.txt                                |   28 \u001b[32m+\u001b[m\n",
            " environment.yml                          |   38 \u001b[32m+\u001b[m\n",
            " models/cnn/sb1.pt                        |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb10_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb10_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb10_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb10_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb10_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb10_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb1_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb1_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb1_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb1_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb1_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb1_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb2_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb2_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb2_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb2_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb2_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb2_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb3_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb3_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb3_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb3_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb3_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb3_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb4_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb4_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb4_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb4_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb4_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb4_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb5_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb5_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb5_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb5_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb5_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb5_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb6_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb6_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb6_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb6_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb6_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb6_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb7_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb7_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb7_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb7_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb7_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb7_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb8_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb8_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb8_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb8_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb8_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb8_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb9_t1.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb9_t2.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb9_t3.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb9_t4.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb9_t5.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/cnn/sb9_t6.pt                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb10_t1.pt                   |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb10_t2.pt                   |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb10_t3.pt                   |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb10_t4.pt                   |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb10_t5.pt                   |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb10_t6.pt                   |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb1_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb1_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb1_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb1_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb1_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb1_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb2_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb2_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb2_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb2_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb2_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb2_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb3_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb3_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb3_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb3_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb3_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb3_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb4_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb4_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb4_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb4_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb4_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb4_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb5_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb5_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb5_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb5_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb5_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb5_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb6_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb6_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb6_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb6_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb6_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb6_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb7_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb7_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb7_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb7_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb7_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb7_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb8_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb8_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb8_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb8_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb8_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb8_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb9_t1.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb9_t2.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb9_t3.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb9_t4.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb9_t5.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/ecnn/sb9_t6.pt                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m4775266\u001b[m bytes\n",
            " models/model_1.bin                       |  Bin \u001b[31m4775266\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " results/cv/accuracy.csv                  | 1441 \u001b[32m++++++++++++++++++++++++++++++\u001b[m\n",
            " results/cv/reliability.csv               |  361 \u001b[32m++++++++\u001b[m\n",
            " retrain_run.sh                           |    9 \u001b[32m+\u001b[m\n",
            " src/__init__.py                          |    2 \u001b[32m+\u001b[m\n",
            " src/__pycache__/helps.cpython-37.pyc     |  Bin \u001b[31m3464\u001b[m -> \u001b[32m0\u001b[m bytes\n",
            " src/__pycache__/helps_pre.cpython-37.pyc |  Bin \u001b[31m0\u001b[m -> \u001b[32m1462\u001b[m bytes\n",
            " src/__pycache__/helps_pro.cpython-37.pyc |  Bin \u001b[31m0\u001b[m -> \u001b[32m4978\u001b[m bytes\n",
            " src/__pycache__/utils.cpython-37.pyc     |  Bin \u001b[31m4998\u001b[m -> \u001b[32m7034\u001b[m bytes\n",
            " src/data_pre.py                          |    0\n",
            " src/helps.py                             |  140 \u001b[31m---\u001b[m\n",
            " src/helps_pre.py                         |   49 \u001b[32m+\u001b[m\n",
            " src/helps_pro.py                         |  216 \u001b[32m+++++\u001b[m\n",
            " src/main.py                              |    1 \u001b[31m-\u001b[m\n",
            " src/models.py                            |    0\n",
            " src/retrain.py                           |  105 \u001b[32m+++\u001b[m\n",
            " src/temp.py                              |    1 \u001b[32m+\u001b[m\n",
            " src/testing.py                           |  103 \u001b[32m+++\u001b[m\n",
            " src/train.py                             |  206 \u001b[32m+++\u001b[m\u001b[31m--\u001b[m\n",
            " src/utils.py                             |  169 \u001b[32m+++\u001b[m\u001b[31m-\u001b[m\n",
            " study/cnn/sb1/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb1/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb1/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb1/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb1/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb1/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb10/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb10/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb10/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb10/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb10/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb10/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb2/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb2/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb2/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb2/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb2/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb2/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb3/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb3/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb3/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb3/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb3/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb3/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb4/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb4/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb4/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb4/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb4/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb4/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb5/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb5/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb5/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb5/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb5/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb5/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb6/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb6/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb6/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb6/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb6/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb6/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb7/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb7/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb7/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb7/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb7/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb7/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb8/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb8/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb8/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb8/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb8/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb8/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb9/t1.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb9/t2.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb9/t3.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb9/t4.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb9/t5.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/cnn/sb9/t6.db                      |  Bin \u001b[31m0\u001b[m -> \u001b[32m118784\u001b[m bytes\n",
            " study/ecnn/sb1/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb1/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb1/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb1/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb1/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb1/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb10/t1.db                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb10/t2.db                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb10/t3.db                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb10/t4.db                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb10/t5.db                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb10/t6.db                    |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb2/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb2/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb2/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb2/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb2/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb2/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb3/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb3/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb3/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb3/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb3/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb3/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb4/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb4/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb4/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb4/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb4/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb4/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb5/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb5/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb5/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb5/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb5/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb5/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb6/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb6/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb6/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb6/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb6/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb6/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb7/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb7/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb7/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb7/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb7/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb7/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb8/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb8/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb8/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb8/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb8/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb8/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb9/t1.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb9/t2.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb9/t3.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb9/t4.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb9/t5.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " study/ecnn/sb9/t6.db                     |  Bin \u001b[31m0\u001b[m -> \u001b[32m126976\u001b[m bytes\n",
            " test_run.sh                              |   11 \u001b[32m+\u001b[m\n",
            " run.sh => train_run.sh                   |    2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 327 files changed, 2619 insertions(+), 264 deletions(-)\n",
            " rename src/create_folds.py => __init__.py (100%)\n",
            " create mode 100644 data/NinaproDB5/raw/sb10_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb10_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb10_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb10_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb10_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb10_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb1_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb1_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb1_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb1_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb1_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb1_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb2_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb2_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb2_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb2_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb2_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb2_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb3_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb3_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb3_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb3_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb3_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb3_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb4_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb4_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb4_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb4_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb4_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb4_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb5_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb5_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb5_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb5_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb5_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb5_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb6_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb6_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb6_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb6_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb6_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb6_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb7_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb7_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb7_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb7_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb7_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb7_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb8_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb8_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb8_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb8_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb8_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb8_trial6.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb9_trial1.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb9_trial2.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb9_trial3.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb9_trial4.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb9_trial5.pkl\n",
            " create mode 100644 data/NinaproDB5/raw/sb9_trial6.pkl\n",
            " create mode 100644 draft.txt\n",
            " create mode 100644 environment.yml\n",
            " create mode 100644 models/cnn/sb1.pt\n",
            " create mode 100644 models/cnn/sb10_t1.pt\n",
            " create mode 100644 models/cnn/sb10_t2.pt\n",
            " create mode 100644 models/cnn/sb10_t3.pt\n",
            " create mode 100644 models/cnn/sb10_t4.pt\n",
            " create mode 100644 models/cnn/sb10_t5.pt\n",
            " create mode 100644 models/cnn/sb10_t6.pt\n",
            " create mode 100644 models/cnn/sb1_t1.pt\n",
            " create mode 100644 models/cnn/sb1_t2.pt\n",
            " create mode 100644 models/cnn/sb1_t3.pt\n",
            " create mode 100644 models/cnn/sb1_t4.pt\n",
            " create mode 100644 models/cnn/sb1_t5.pt\n",
            " create mode 100644 models/cnn/sb1_t6.pt\n",
            " create mode 100644 models/cnn/sb2_t1.pt\n",
            " create mode 100644 models/cnn/sb2_t2.pt\n",
            " create mode 100644 models/cnn/sb2_t3.pt\n",
            " create mode 100644 models/cnn/sb2_t4.pt\n",
            " create mode 100644 models/cnn/sb2_t5.pt\n",
            " create mode 100644 models/cnn/sb2_t6.pt\n",
            " create mode 100644 models/cnn/sb3_t1.pt\n",
            " create mode 100644 models/cnn/sb3_t2.pt\n",
            " create mode 100644 models/cnn/sb3_t3.pt\n",
            " create mode 100644 models/cnn/sb3_t4.pt\n",
            " create mode 100644 models/cnn/sb3_t5.pt\n",
            " create mode 100644 models/cnn/sb3_t6.pt\n",
            " create mode 100644 models/cnn/sb4_t1.pt\n",
            " create mode 100644 models/cnn/sb4_t2.pt\n",
            " create mode 100644 models/cnn/sb4_t3.pt\n",
            " create mode 100644 models/cnn/sb4_t4.pt\n",
            " create mode 100644 models/cnn/sb4_t5.pt\n",
            " create mode 100644 models/cnn/sb4_t6.pt\n",
            " create mode 100644 models/cnn/sb5_t1.pt\n",
            " create mode 100644 models/cnn/sb5_t2.pt\n",
            " create mode 100644 models/cnn/sb5_t3.pt\n",
            " create mode 100644 models/cnn/sb5_t4.pt\n",
            " create mode 100644 models/cnn/sb5_t5.pt\n",
            " create mode 100644 models/cnn/sb5_t6.pt\n",
            " create mode 100644 models/cnn/sb6_t1.pt\n",
            " create mode 100644 models/cnn/sb6_t2.pt\n",
            " create mode 100644 models/cnn/sb6_t3.pt\n",
            " create mode 100644 models/cnn/sb6_t4.pt\n",
            " create mode 100644 models/cnn/sb6_t5.pt\n",
            " create mode 100644 models/cnn/sb6_t6.pt\n",
            " create mode 100644 models/cnn/sb7_t1.pt\n",
            " create mode 100644 models/cnn/sb7_t2.pt\n",
            " create mode 100644 models/cnn/sb7_t3.pt\n",
            " create mode 100644 models/cnn/sb7_t4.pt\n",
            " create mode 100644 models/cnn/sb7_t5.pt\n",
            " create mode 100644 models/cnn/sb7_t6.pt\n",
            " create mode 100644 models/cnn/sb8_t1.pt\n",
            " create mode 100644 models/cnn/sb8_t2.pt\n",
            " create mode 100644 models/cnn/sb8_t3.pt\n",
            " create mode 100644 models/cnn/sb8_t4.pt\n",
            " create mode 100644 models/cnn/sb8_t5.pt\n",
            " create mode 100644 models/cnn/sb8_t6.pt\n",
            " create mode 100644 models/cnn/sb9_t1.pt\n",
            " create mode 100644 models/cnn/sb9_t2.pt\n",
            " create mode 100644 models/cnn/sb9_t3.pt\n",
            " create mode 100644 models/cnn/sb9_t4.pt\n",
            " create mode 100644 models/cnn/sb9_t5.pt\n",
            " create mode 100644 models/cnn/sb9_t6.pt\n",
            " create mode 100644 models/ecnn/sb10_t1.pt\n",
            " create mode 100644 models/ecnn/sb10_t2.pt\n",
            " create mode 100644 models/ecnn/sb10_t3.pt\n",
            " create mode 100644 models/ecnn/sb10_t4.pt\n",
            " create mode 100644 models/ecnn/sb10_t5.pt\n",
            " create mode 100644 models/ecnn/sb10_t6.pt\n",
            " create mode 100644 models/ecnn/sb1_t1.pt\n",
            " create mode 100644 models/ecnn/sb1_t2.pt\n",
            " create mode 100644 models/ecnn/sb1_t3.pt\n",
            " create mode 100644 models/ecnn/sb1_t4.pt\n",
            " create mode 100644 models/ecnn/sb1_t5.pt\n",
            " create mode 100644 models/ecnn/sb1_t6.pt\n",
            " create mode 100644 models/ecnn/sb2_t1.pt\n",
            " create mode 100644 models/ecnn/sb2_t2.pt\n",
            " create mode 100644 models/ecnn/sb2_t3.pt\n",
            " create mode 100644 models/ecnn/sb2_t4.pt\n",
            " create mode 100644 models/ecnn/sb2_t5.pt\n",
            " create mode 100644 models/ecnn/sb2_t6.pt\n",
            " create mode 100644 models/ecnn/sb3_t1.pt\n",
            " create mode 100644 models/ecnn/sb3_t2.pt\n",
            " create mode 100644 models/ecnn/sb3_t3.pt\n",
            " create mode 100644 models/ecnn/sb3_t4.pt\n",
            " create mode 100644 models/ecnn/sb3_t5.pt\n",
            " create mode 100644 models/ecnn/sb3_t6.pt\n",
            " create mode 100644 models/ecnn/sb4_t1.pt\n",
            " create mode 100644 models/ecnn/sb4_t2.pt\n",
            " create mode 100644 models/ecnn/sb4_t3.pt\n",
            " create mode 100644 models/ecnn/sb4_t4.pt\n",
            " create mode 100644 models/ecnn/sb4_t5.pt\n",
            " create mode 100644 models/ecnn/sb4_t6.pt\n",
            " create mode 100644 models/ecnn/sb5_t1.pt\n",
            " create mode 100644 models/ecnn/sb5_t2.pt\n",
            " create mode 100644 models/ecnn/sb5_t3.pt\n",
            " create mode 100644 models/ecnn/sb5_t4.pt\n",
            " create mode 100644 models/ecnn/sb5_t5.pt\n",
            " create mode 100644 models/ecnn/sb5_t6.pt\n",
            " create mode 100644 models/ecnn/sb6_t1.pt\n",
            " create mode 100644 models/ecnn/sb6_t2.pt\n",
            " create mode 100644 models/ecnn/sb6_t3.pt\n",
            " create mode 100644 models/ecnn/sb6_t4.pt\n",
            " create mode 100644 models/ecnn/sb6_t5.pt\n",
            " create mode 100644 models/ecnn/sb6_t6.pt\n",
            " create mode 100644 models/ecnn/sb7_t1.pt\n",
            " create mode 100644 models/ecnn/sb7_t2.pt\n",
            " create mode 100644 models/ecnn/sb7_t3.pt\n",
            " create mode 100644 models/ecnn/sb7_t4.pt\n",
            " create mode 100644 models/ecnn/sb7_t5.pt\n",
            " create mode 100644 models/ecnn/sb7_t6.pt\n",
            " create mode 100644 models/ecnn/sb8_t1.pt\n",
            " create mode 100644 models/ecnn/sb8_t2.pt\n",
            " create mode 100644 models/ecnn/sb8_t3.pt\n",
            " create mode 100644 models/ecnn/sb8_t4.pt\n",
            " create mode 100644 models/ecnn/sb8_t5.pt\n",
            " create mode 100644 models/ecnn/sb8_t6.pt\n",
            " create mode 100644 models/ecnn/sb9_t1.pt\n",
            " create mode 100644 models/ecnn/sb9_t2.pt\n",
            " create mode 100644 models/ecnn/sb9_t3.pt\n",
            " create mode 100644 models/ecnn/sb9_t4.pt\n",
            " create mode 100644 models/ecnn/sb9_t5.pt\n",
            " create mode 100644 models/ecnn/sb9_t6.pt\n",
            " delete mode 100644 models/model_1.bin\n",
            " create mode 100644 results/cv/accuracy.csv\n",
            " create mode 100644 results/cv/reliability.csv\n",
            " create mode 100644 retrain_run.sh\n",
            " create mode 100644 src/__init__.py\n",
            " delete mode 100644 src/__pycache__/helps.cpython-37.pyc\n",
            " create mode 100644 src/__pycache__/helps_pre.cpython-37.pyc\n",
            " create mode 100644 src/__pycache__/helps_pro.cpython-37.pyc\n",
            " delete mode 100644 src/data_pre.py\n",
            " delete mode 100644 src/helps.py\n",
            " create mode 100644 src/helps_pre.py\n",
            " create mode 100644 src/helps_pro.py\n",
            " delete mode 100644 src/main.py\n",
            " delete mode 100644 src/models.py\n",
            " create mode 100644 src/retrain.py\n",
            " create mode 100644 src/temp.py\n",
            " create mode 100644 src/testing.py\n",
            " create mode 100644 study/cnn/sb1/t1.db\n",
            " create mode 100644 study/cnn/sb1/t2.db\n",
            " create mode 100644 study/cnn/sb1/t3.db\n",
            " create mode 100644 study/cnn/sb1/t4.db\n",
            " create mode 100644 study/cnn/sb1/t5.db\n",
            " create mode 100644 study/cnn/sb1/t6.db\n",
            " create mode 100644 study/cnn/sb10/t1.db\n",
            " create mode 100644 study/cnn/sb10/t2.db\n",
            " create mode 100644 study/cnn/sb10/t3.db\n",
            " create mode 100644 study/cnn/sb10/t4.db\n",
            " create mode 100644 study/cnn/sb10/t5.db\n",
            " create mode 100644 study/cnn/sb10/t6.db\n",
            " create mode 100644 study/cnn/sb2/t1.db\n",
            " create mode 100644 study/cnn/sb2/t2.db\n",
            " create mode 100644 study/cnn/sb2/t3.db\n",
            " create mode 100644 study/cnn/sb2/t4.db\n",
            " create mode 100644 study/cnn/sb2/t5.db\n",
            " create mode 100644 study/cnn/sb2/t6.db\n",
            " create mode 100644 study/cnn/sb3/t1.db\n",
            " create mode 100644 study/cnn/sb3/t2.db\n",
            " create mode 100644 study/cnn/sb3/t3.db\n",
            " create mode 100644 study/cnn/sb3/t4.db\n",
            " create mode 100644 study/cnn/sb3/t5.db\n",
            " create mode 100644 study/cnn/sb3/t6.db\n",
            " create mode 100644 study/cnn/sb4/t1.db\n",
            " create mode 100644 study/cnn/sb4/t2.db\n",
            " create mode 100644 study/cnn/sb4/t3.db\n",
            " create mode 100644 study/cnn/sb4/t4.db\n",
            " create mode 100644 study/cnn/sb4/t5.db\n",
            " create mode 100644 study/cnn/sb4/t6.db\n",
            " create mode 100644 study/cnn/sb5/t1.db\n",
            " create mode 100644 study/cnn/sb5/t2.db\n",
            " create mode 100644 study/cnn/sb5/t3.db\n",
            " create mode 100644 study/cnn/sb5/t4.db\n",
            " create mode 100644 study/cnn/sb5/t5.db\n",
            " create mode 100644 study/cnn/sb5/t6.db\n",
            " create mode 100644 study/cnn/sb6/t1.db\n",
            " create mode 100644 study/cnn/sb6/t2.db\n",
            " create mode 100644 study/cnn/sb6/t3.db\n",
            " create mode 100644 study/cnn/sb6/t4.db\n",
            " create mode 100644 study/cnn/sb6/t5.db\n",
            " create mode 100644 study/cnn/sb6/t6.db\n",
            " create mode 100644 study/cnn/sb7/t1.db\n",
            " create mode 100644 study/cnn/sb7/t2.db\n",
            " create mode 100644 study/cnn/sb7/t3.db\n",
            " create mode 100644 study/cnn/sb7/t4.db\n",
            " create mode 100644 study/cnn/sb7/t5.db\n",
            " create mode 100644 study/cnn/sb7/t6.db\n",
            " create mode 100644 study/cnn/sb8/t1.db\n",
            " create mode 100644 study/cnn/sb8/t2.db\n",
            " create mode 100644 study/cnn/sb8/t3.db\n",
            " create mode 100644 study/cnn/sb8/t4.db\n",
            " create mode 100644 study/cnn/sb8/t5.db\n",
            " create mode 100644 study/cnn/sb8/t6.db\n",
            " create mode 100644 study/cnn/sb9/t1.db\n",
            " create mode 100644 study/cnn/sb9/t2.db\n",
            " create mode 100644 study/cnn/sb9/t3.db\n",
            " create mode 100644 study/cnn/sb9/t4.db\n",
            " create mode 100644 study/cnn/sb9/t5.db\n",
            " create mode 100644 study/cnn/sb9/t6.db\n",
            " create mode 100644 study/ecnn/sb1/t1.db\n",
            " create mode 100644 study/ecnn/sb1/t2.db\n",
            " create mode 100644 study/ecnn/sb1/t3.db\n",
            " create mode 100644 study/ecnn/sb1/t4.db\n",
            " create mode 100644 study/ecnn/sb1/t5.db\n",
            " create mode 100644 study/ecnn/sb1/t6.db\n",
            " create mode 100644 study/ecnn/sb10/t1.db\n",
            " create mode 100644 study/ecnn/sb10/t2.db\n",
            " create mode 100644 study/ecnn/sb10/t3.db\n",
            " create mode 100644 study/ecnn/sb10/t4.db\n",
            " create mode 100644 study/ecnn/sb10/t5.db\n",
            " create mode 100644 study/ecnn/sb10/t6.db\n",
            " create mode 100644 study/ecnn/sb2/t1.db\n",
            " create mode 100644 study/ecnn/sb2/t2.db\n",
            " create mode 100644 study/ecnn/sb2/t3.db\n",
            " create mode 100644 study/ecnn/sb2/t4.db\n",
            " create mode 100644 study/ecnn/sb2/t5.db\n",
            " create mode 100644 study/ecnn/sb2/t6.db\n",
            " create mode 100644 study/ecnn/sb3/t1.db\n",
            " create mode 100644 study/ecnn/sb3/t2.db\n",
            " create mode 100644 study/ecnn/sb3/t3.db\n",
            " create mode 100644 study/ecnn/sb3/t4.db\n",
            " create mode 100644 study/ecnn/sb3/t5.db\n",
            " create mode 100644 study/ecnn/sb3/t6.db\n",
            " create mode 100644 study/ecnn/sb4/t1.db\n",
            " create mode 100644 study/ecnn/sb4/t2.db\n",
            " create mode 100644 study/ecnn/sb4/t3.db\n",
            " create mode 100644 study/ecnn/sb4/t4.db\n",
            " create mode 100644 study/ecnn/sb4/t5.db\n",
            " create mode 100644 study/ecnn/sb4/t6.db\n",
            " create mode 100644 study/ecnn/sb5/t1.db\n",
            " create mode 100644 study/ecnn/sb5/t2.db\n",
            " create mode 100644 study/ecnn/sb5/t3.db\n",
            " create mode 100644 study/ecnn/sb5/t4.db\n",
            " create mode 100644 study/ecnn/sb5/t5.db\n",
            " create mode 100644 study/ecnn/sb5/t6.db\n",
            " create mode 100644 study/ecnn/sb6/t1.db\n",
            " create mode 100644 study/ecnn/sb6/t2.db\n",
            " create mode 100644 study/ecnn/sb6/t3.db\n",
            " create mode 100644 study/ecnn/sb6/t4.db\n",
            " create mode 100644 study/ecnn/sb6/t5.db\n",
            " create mode 100644 study/ecnn/sb6/t6.db\n",
            " create mode 100644 study/ecnn/sb7/t1.db\n",
            " create mode 100644 study/ecnn/sb7/t2.db\n",
            " create mode 100644 study/ecnn/sb7/t3.db\n",
            " create mode 100644 study/ecnn/sb7/t4.db\n",
            " create mode 100644 study/ecnn/sb7/t5.db\n",
            " create mode 100644 study/ecnn/sb7/t6.db\n",
            " create mode 100644 study/ecnn/sb8/t1.db\n",
            " create mode 100644 study/ecnn/sb8/t2.db\n",
            " create mode 100644 study/ecnn/sb8/t3.db\n",
            " create mode 100644 study/ecnn/sb8/t4.db\n",
            " create mode 100644 study/ecnn/sb8/t5.db\n",
            " create mode 100644 study/ecnn/sb8/t6.db\n",
            " create mode 100644 study/ecnn/sb9/t1.db\n",
            " create mode 100644 study/ecnn/sb9/t2.db\n",
            " create mode 100644 study/ecnn/sb9/t3.db\n",
            " create mode 100644 study/ecnn/sb9/t4.db\n",
            " create mode 100644 study/ecnn/sb9/t5.db\n",
            " create mode 100644 study/ecnn/sb9/t6.db\n",
            " create mode 100644 test_run.sh\n",
            " rename run.sh => train_run.sh (64%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUYBoAhaVyZR",
        "outputId": "89c92a32-4215-403e-efa7-95fde5db8c00"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error: pathspec 'origin/feature-20210203-devtest' did not match any file(s) known to git.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPl_ZYMQXd8R",
        "outputId": "986cc00d-0acc-4061-8a53-ed26019751cf"
      },
      "source": [
        "!git branch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* \u001b[32mnewbranch\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxyr6Dtg3R2V"
      },
      "source": [
        "!cd src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HokWEEH3lkx",
        "outputId": "e6cdb0eb-1adb-46c4-e683-41adadac8f65"
      },
      "source": [
        "!ls \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\t    example.db\t\t\t  logs\t  results  src\n",
            "Demo.ipynb  hyperparameter_importance.py  models  run.sh   study\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do-kZnPiSjqc"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.special as sc\n",
        "import torch\n",
        "import optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpVAUWyp4DC0"
      },
      "source": [
        "loaded_study = optuna.load_study(study_name=\"STUDY\", storage=\"sqlite:///study/ecnn/sb2/temp.db\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0K5KpP3g7802",
        "outputId": "eda8e4d9-c97b-4500-a3e3-f8fc0c81cc17"
      },
      "source": [
        "#fig = \n",
        "loaded_study = optuna.load_study(study_name=\"STUDY\", storage=\"sqlite:///study/ecnn/sb4/temp.db\")\n",
        "optuna.visualization.plot_param_importances(loaded_study)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"5bb1665d-ee2a-4004-b8e2-d1caf056d414\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"5bb1665d-ee2a-4004-b8e2-d1caf056d414\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '5bb1665d-ee2a-4004-b8e2-d1caf056d414',\n",
              "                        [{\"cliponaxis\": false, \"hovertemplate\": [\"batch_size (IntUniformDistribution): 0.0004449568114428966<extra></extra>\", \"evi_fun (CategoricalDistribution): 0.01609565722788814<extra></extra>\", \"lr (LogUniformDistribution): 0.0976085661930697<extra></extra>\", \"optimizer (CategoricalDistribution): 0.405573756584745<extra></extra>\", \"KL (IntUniformDistribution): 0.48027706318285435<extra></extra>\"], \"marker\": {\"color\": [\"rgb(8,81,156)\", \"rgb(66,146,198)\", \"rgb(8,48,107)\", \"rgb(66,146,198)\", \"rgb(8,81,156)\"]}, \"orientation\": \"h\", \"text\": [\"0.0004449568114428966\", \"0.01609565722788814\", \"0.0976085661930697\", \"0.405573756584745\", \"0.48027706318285435\"], \"textposition\": \"outside\", \"texttemplate\": \"%{text:.2f}\", \"type\": \"bar\", \"x\": [0.0004449568114428966, 0.01609565722788814, 0.0976085661930697, 0.405573756584745, 0.48027706318285435], \"y\": [\"batch_size\", \"evi_fun\", \"lr\", \"optimizer\", \"KL\"]}],\n",
              "                        {\"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Hyperparameter Importances\"}, \"xaxis\": {\"title\": {\"text\": \"Importance for Objective Value\"}}, \"yaxis\": {\"title\": {\"text\": \"Hyperparameter\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5bb1665d-ee2a-4004-b8e2-d1caf056d414');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9bC2zxTJ9fxb",
        "outputId": "c99356a8-de7d-4e0f-ffc3-cffa248c4f37"
      },
      "source": [
        "loaded_study = optuna.load_study(study_name=\"STUDY\", storage=\"sqlite:///study/ecnn/sb4/temp.db\")\n",
        "temp = optuna.importance.get_param_importances(loaded_study)\n",
        "trial = loaded_study.best_trial\n",
        "'''\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor key, value in trial.params.items():\\n    print(\"    {}: {}\".format(key, value))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD7jwYBDK4MP",
        "outputId": "56d933ad-c6b5-40e2-f8f0-300f0b3eb992"
      },
      "source": [
        "print(trial.params.items())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_items([('KL', 0), ('batch_size', 128), ('evi_fun', 'softplus'), ('lr', 0.008361949732894601), ('optimizer', 'Adam')])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKuAtI-9FkFg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GfFeYTeFwL4",
        "outputId": "17929be5-d032-4e3c-f753-1d680a09e32a"
      },
      "source": [
        "hyperparams_ecnn = ['optimizer', 'lr', 'batch_size', 'KL', 'evi_fun']\n",
        "h_ecnn_i = {k:[] for k in hyperparams_ecnn}\n",
        "best_h_ecnn = {k:[] for k in hyperparams_ecnn}\n",
        "print(h_ecnn_i)\n",
        "\n",
        "hyperparams_cnn = ['optimizer', 'lr', 'batch_size']\n",
        "h_cnn_i = {k:[] for k in hyperparams_cnn}\n",
        "best_h_cnn = {k:[] for k in hyperparams_cnn}\n",
        "print(h_cnn_i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'optimizer': [], 'lr': [], 'batch_size': [], 'KL': [], 'evi_fun': []}\n",
            "{'optimizer': [], 'lr': [], 'batch_size': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SMfxmFjGm6S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "essf0sZrGtH2",
        "outputId": "66e8e128-89c3-474f-d32e-25aab3005821"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cnn\n",
            "ecnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRFxsk0z9vhq"
      },
      "source": [
        "m = ['cnn','ecnn']\n",
        "for i in m:\n",
        "    path = 'sqlite:///study/'+ i\n",
        "    for sb_n in range(1,10):\n",
        "        temp_path = path + '/sb' +str(sb_n) + '/temp.db'    \n",
        "        loaded_study = optuna.load_study(study_name=\"STUDY\", storage=temp_path)\n",
        "        temp_i = optuna.importance.get_param_importances(loaded_study)\n",
        "        temp_best_trial = loaded_study.best_trial\n",
        "        if i == 'cnn':\n",
        "            for key, value in temp_best_trial.params.items():\n",
        "                h_cnn_i[key].append(temp_i[key])\n",
        "                best_h_cnn[key].append(value)\n",
        "        else:\n",
        "            for key, value in temp_best_trial.params.items():\n",
        "                h_ecnn_i[key].append(temp_i[key])\n",
        "                best_h_ecnn[key].append(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4CybSTfcnG6",
        "outputId": "5495c0ae-9d8f-429c-bb01-11b24be27eb1"
      },
      "source": [
        "best_h_cnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': [128, 128, 128, 128, 128, 256, 128, 128, 256],\n",
              " 'lr': [0.00495610172261532,\n",
              "  0.0023141671531019836,\n",
              "  0.0024673208932579037,\n",
              "  0.004338440356058421,\n",
              "  0.006439442638960212,\n",
              "  0.0025681149610516517,\n",
              "  0.0030925981337863733,\n",
              "  0.0016029716811406882,\n",
              "  0.0028901754718335527],\n",
              " 'optimizer': ['Adam',\n",
              "  'RMSprop',\n",
              "  'RMSprop',\n",
              "  'RMSprop',\n",
              "  'Adam',\n",
              "  'RMSprop',\n",
              "  'RMSprop',\n",
              "  'RMSprop',\n",
              "  'RMSprop']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amL3m0QgSrQc",
        "outputId": "fa23c53e-5ceb-4074-cfb2-980a896650d6"
      },
      "source": [
        "###  Calculate Vacuity and dissonance \n",
        "\n",
        "def Bal(a,b):\n",
        "    if a*b !=0:\n",
        "        output = 1-abs(a-b)/(a+b)\n",
        "    else:\n",
        "        output = 0\n",
        "    return output        \n",
        "\n",
        "#evidence = np.array([99]*12)\n",
        "evidence = np.array([4,9,0])\n",
        "alpha = evidence + 1\n",
        "prob_SL = alpha / np.sum(alpha)\n",
        "class_num = len(evidence)\n",
        "total_evidence = np.sum(alpha)\n",
        "\n",
        "u_va = class_num / total_evidence\n",
        "\n",
        "print('The vacuity is: %.2f' %(u_va))\n",
        "\n",
        "belief = evidence/total_evidence\n",
        "belief = belief.tolist()\n",
        "u_dis = 0.0\n",
        "for index_k,k in enumerate(belief):\n",
        "    temp0 = 0.0\n",
        "    temp1 = 0.0\n",
        "    for index_j,j in enumerate(belief):\n",
        "        if index_j!=index_k:\n",
        "            temp0 += j*Bal(k,j)\n",
        "            temp1 += j\n",
        "    if temp1!=0:\n",
        "        u_dis += k*temp0/temp1\n",
        "print('The dissonance is: %.2f' %(u_dis))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The vacuity is: 0.19\n",
            "The dissonance is: 0.50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IneNE9R9tGD",
        "outputId": "1735d2b5-259d-4aeb-dc52-5de0bb2233e1"
      },
      "source": [
        "import torch\n",
        "#alpha = torch.ones([1, 12], dtype=torch.float32)\n",
        "belief = torch.tensor([[0.3,0.3,0.0],[0.1,0.1,0.1]], dtype=torch.float32,requires_grad=True)\n",
        "k_class = 3\n",
        "\n",
        "'''\n",
        "def Bal(a,b,batch_n):\n",
        "    output = torch.where(a*b>0,1.0-torch.abs(a-b)/(a+b),0)\n",
        "    if a*b !=0:\n",
        "        output = 1.0-torch.abs(a-b)/(a+b)\n",
        "    else:\n",
        "        output = torch.Tensor.zeros(batch_n,1)\n",
        "    return output\n",
        "'''\n",
        "\n",
        "batch_n = belief.size()[0]\n",
        "u_dis = torch.zeros(batch_n,1)\n",
        "for index_k in range(k_class):\n",
        "    temp0 = torch.zeros(batch_n,1)\n",
        "    temp1 = torch.zeros(batch_n,1)\n",
        "    for index_j in range(k_class):\n",
        "        if index_j!=index_k:\n",
        "            k = belief[:,index_k].reshape(batch_n ,1)\n",
        "            j = belief[:,index_j].reshape(batch_n ,1)\n",
        "            temp0 += j*(1.0-torch.abs(k-j)/(k+j+1e-8))\n",
        "            #torch.where(k*j>0.0,1.0-torch.abs(k-j)/(k+j),torch.zeros(batch_n,1))\n",
        "            temp1 += j\n",
        "    u_dis += k*temp0/(temp1+1e-8)\n",
        "\n",
        "u_dis.sum().backward()\n",
        "print(belief.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0000,  1.0000, -2.0000],\n",
            "        [ 1.0000,  1.0000,  1.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw-jy4FdESyv",
        "outputId": "8d2259bd-693e-4aa7-ed18-efb9d4763be8"
      },
      "source": [
        "import numpy as np\n",
        "a = np.array([[1.0],[2.0],[3.0]])\n",
        "b = np.array([[2.0],[1.0],[10.0]])\n",
        "c = np.concatenate((a,b),axis=1)\n",
        "print(np.shape(a))\n",
        "d = np.max(c,axis=1,keepdims=True)\n",
        "print(np.shape(d))\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 1)\n",
            "(3, 1)\n",
            "[[ 2.]\n",
            " [ 2.]\n",
            " [10.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM2AHjq36bkw",
        "outputId": "29613d98-11a3-4c0c-8841-50208d177b80"
      },
      "source": [
        "import torch\n",
        "x_data = [1.0, 2.0, 3.0]\n",
        "y_data = [2.0, 4.0, 6.0]\n",
        " \n",
        "w = torch.Tensor([1.0]) # w1.0\n",
        "w.requires_grad = True # \n",
        "\n",
        "\n",
        "#print(w.grad.data.type())\n",
        "\n",
        "\n",
        "\n",
        "def forward(x):\n",
        "    return x*w  # wTensor\n",
        " \n",
        " \n",
        "def loss(x, y):\n",
        "    y_pred = forward(x)\n",
        "    return (y_pred - y)**2\n",
        " \n",
        "print(\"predict (before training)\", 4, forward(4).item())\n",
        " \n",
        "for epoch in range(10):\n",
        "    for x, y in zip(x_data, y_data):\n",
        "        l =loss(x,y) # ltensor forward, compute the loss\n",
        "        l.backward() #  backward,compute grad for Tensor whose requires_grad set to True\n",
        "\n",
        "        print(w.data.type())\n",
        "        print(w.grad.data.type())\n",
        "        break\n",
        "        print('\\tgrad:', x, y, w.grad.item())\n",
        "        w.data = w.data - 0.01 * w.grad.data   # gradtensor\n",
        " \n",
        "        w.grad.data.zero_() # after update, remember set the grad to zero\n",
        " \n",
        "    print('progress:', epoch, l.item()) # lossl.itemlltensor\n",
        " \n",
        "print(\"predict (after training)\", 4, forward(4).item())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (before training) 4 4.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 0 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 1 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 2 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 3 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 4 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 5 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 6 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 7 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 8 1.0\n",
            "torch.FloatTensor\n",
            "torch.FloatTensor\n",
            "progress: 9 1.0\n",
            "predict (after training) 4 4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HElo7ysrPx2B",
        "outputId": "e35d615e-becf-4338-c55c-891bd340c820"
      },
      "source": [
        "evidence = np.array([19]*12)\n",
        "print(evidence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19 19 19 19 19 19 19 19 19 19 19 19]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6saVw18emyO"
      },
      "source": [
        "### Loss function\n",
        "def loss_cal(para):\n",
        "    y_label = np.array([1,0,0,0,0,0,0,0,0,0,0,0])\n",
        "    \n",
        "    # parameters: alphas\n",
        "    S = np.sum(para)\n",
        "    pred = para/S\n",
        "    pred_err = np.sum(np.square(pred-y_label))\n",
        "\n",
        "    pred_var = np.sum(pred*(1-pred)/(S+1))\n",
        "    #pred_var = np.sum(pred*(1-pred))\n",
        "    return pred_err,pred_var\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0epVWITNvdM7"
      },
      "source": [
        "def kl_divergence(para,n_class=3):\n",
        "    beta = np.ones()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPsW7dAUf0D-",
        "outputId": "1a3dca45-f736-4494-9e99-ec506631e595"
      },
      "source": [
        "alphas = np.array([10,12,10,10,10,10,10,10,10,10,10,10])\n",
        "pred_err,pred_var = loss_cal(alphas)\n",
        "print(pred_err,pred_var,pred_err+pred_var)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9196452566514377 0.007450571683894748 0.9270958283353324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfzpqLR7grAT",
        "outputId": "f00095a4-e4ae-4ef9-ae9f-8476a5ef1bc0"
      },
      "source": [
        "prob = np.array([0,0.5,0])\n",
        "print(mse_loss(prob))\n",
        "prob = np.array([0,0.4,0.3])\n",
        "print(mse_loss(prob))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.25\n",
            "1.2500000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84t6pqoyVro8",
        "outputId": "40ec5b89-59f7-4f8b-f457-7d5416b30121"
      },
      "source": [
        "alphas = np.array([1,10,8])\n",
        "alphas = (alphas-1)*(1-np.array([1,0,0]))+1\n",
        "print(alphas)\n",
        "beta = np.ones(3)\n",
        "#beta = np.array([8,8,8])\n",
        "S_alpha = np.sum(alphas)\n",
        "print(S_alpha)\n",
        "S_beta = np.sum(beta)\n",
        "print(S_beta)\n",
        "lnB = sc.gammaln(S_alpha) - np.sum(sc.gammaln(alphas))\n",
        "print(lnB)\n",
        "lnB_uni = np.sum(sc.gammaln(beta)) - sc.gammaln(S_beta)\n",
        "print(lnB_uni)\n",
        "dg0 = sc.digamma(S_alpha)\n",
        "dg1 = sc.digamma(alphas)\n",
        "kl = np.sum((alphas-beta)*(dg1-dg0))+lnB+lnB_uni\n",
        "print(kl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1 10  8]\n",
            "19\n",
            "3.0\n",
            "15.068456366886167\n",
            "-0.6931471805599453\n",
            "2.0642942208994857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tjiyG4l0Zm-",
        "outputId": "c507a773-6709-469c-a7f8-2199f839cd43"
      },
      "source": [
        "y = np.array([1,0,0])\n",
        "kl_alpha = (alphas - 1) * (1 - y) + 1\n",
        "print(kl_alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oYcsz3-y_Uv",
        "outputId": "156a9b28-0552-4532-c915-6fbaad1a150f"
      },
      "source": [
        "import torch\n",
        "#alpha = torch.ones([1, 12], dtype=torch.float32)\n",
        "alpha = torch.tensor([[1,20,1,1,18,1,1,18,1,1,1,1]], dtype=torch.float32)\n",
        "beta = torch.ones([1, 12], dtype=torch.float32)\n",
        "S_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
        "print(S_alpha)\n",
        "S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
        "print(S_beta)\n",
        "lnB = torch.lgamma(S_alpha) - \\\n",
        "    torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n",
        "print(lnB)\n",
        "lnB_uni = torch.sum(torch.lgamma(beta), dim=1,\n",
        "                    keepdim=True) - torch.lgamma(S_beta)\n",
        "print(lnB_uni)\n",
        "dg0 = torch.digamma(S_alpha)\n",
        "dg1 = torch.digamma(alpha)\n",
        "\n",
        "kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1,\n",
        "                keepdim=True) + lnB + lnB_uni\n",
        "\n",
        "print(kl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[65.]])\n",
            "tensor([[12.]])\n",
            "tensor([[98.8182]])\n",
            "tensor([[-17.5023]])\n",
            "tensor([[14.2415]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZtH_l4NnTW4"
      },
      "source": [
        "y = torch.tensor([[1,0,0,0,0,0,0,0,0,0,0,0]], dtype=torch.float32)\n",
        "#print(1-torch.sum(alpha*y,dim=1,keepdim=True)/torch.sum(alpha, dim=1, keepdim=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "IVFxqAT5vukC",
        "outputId": "580f9f2d-eecc-46e2-f64c-8a885a388b37"
      },
      "source": [
        "y2 = torch.tensor([[2,3,0,0,0,0,0,0,0,0,0,0]], dtype=torch.float32)\n",
        "#print(torch.dot(y2,y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c6e45867a60f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: 1D tensors expected, but got 2D and 2D tensors"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IjpBH4ZwN0m",
        "outputId": "fb035918-c4d0-4e5b-9a0f-e23f08d026db"
      },
      "source": [
        "y3 = torch.tensor([[2],[3],[4]])\n",
        "print(y2.reshape(3,4)/y3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 1.5000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM9DCUVEuPI6",
        "outputId": "e737ce19-cc2e-4333-f37e-9cd26734d8ed"
      },
      "source": [
        "value = 5\n",
        "temp = y[y!=torch.max(y)]\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJfj7eGWgPiP",
        "outputId": "d2ce5b3d-f4fa-40cb-8cc7-214c97e71c53"
      },
      "source": [
        "a = [1,2,3]\n",
        "a[0],a[1],a[2] = a[2],a[1],a[0]\n",
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 2, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "RWt3zrocqswV",
        "outputId": "5b077580-83a2-4eff-b921-510dcaec360d"
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt  \n",
        "a = torch.linspace(0, 1, 10, requires_grad=True)\n",
        "b = torch.tensor([0.5], requires_grad=True)\n",
        "loss = torch.abs(a-b)/(a+b+1e-8)\n",
        "loss.backward() \n",
        "plt.plot(a.detach().numpy(), a.grad.detach().numpy(), label='grad')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
            "        1.0000], requires_grad=True)\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d54679741c0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89Jkiu2ngT0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06a99d0-6fdb-46bc-bd9c-b08d207323e7"
      },
      "source": [
        "import torch\n",
        "a = torch.tensor([0.3],requires_grad=True)\n",
        "b = torch.tensor([0.2],requires_grad=True)\n",
        "#loss = torch.where(a*b>0,torch.abs(a-b)/(a+b+1e-8), torch.abs(a-b)/(a+b+1e-8))\n",
        "#loss = torch.where(a*b>0,torch.abs(a-b)/(a+b+1e-8), torch.zeros(1,1))\n",
        "loss = 1-torch.abs(a-b)/(a+b+1e-8)\n",
        "#loss = torch.where(torch.abs(a-b)<=1e-3, 0.5*(a-b)**2/(a+b+1e-8), (1e-3*torch.abs(a-b)-0.5*1e-3**2)/(a+b+1e-8))\n",
        "loss.backward()\n",
        "print(a.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.6000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pCzX9Xt3dde",
        "outputId": "216ffc52-1e5a-4a11-d36d-0363647876e4"
      },
      "source": [
        "a = torch.tensor([[10.,2.0,3.0]],requires_grad=True)\n",
        "b = torch.sum(a,dim=1, keepdim=True)\n",
        "loss = torch.log(b)\n",
        "loss.backward()\n",
        "print(a.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0667, 0.0667, 0.0667]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IidNgRkr5jdP",
        "outputId": "72f0eb27-8fa8-4d8c-b42d-4518c3bf0bad"
      },
      "source": [
        "a = torch.tensor([0.4],requires_grad=True)\n",
        "loss = (a-0.5)/(a+0.5)\n",
        "loss.backward()\n",
        "print(a.grad.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.2346])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbVMxpXcAQr7",
        "outputId": "89c5d4eb-f8e2-4e42-b564-54d39da51df4"
      },
      "source": [
        "index = y>0\n",
        "y2 = torch.tensor([[2,0.5,0,0,0,0,0,0,0,0,0,0]])\n",
        "print(index*y+y2*(~index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "         0.0000, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "SE1vCDJ0oayL",
        "outputId": "f0799a40-70be-457b-dd63-9fef36cb550c"
      },
      "source": [
        "outputs = torch.tensor([[1,0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0,0],[1,0.9,0.8,0.7,0.6,5.5,0.4,0.3,0.2,0.1,0,0]], dtype=torch.float32)\n",
        "print(outputs.size())\n",
        "_, preds = torch.max(outputs, 1)\n",
        "print(preds)\n",
        "\n",
        "print(torch.eq(preds, preds))\n",
        "\n",
        "mean = torch\n",
        "var =  torch.tensor([[0.1,0.3]], dtype=torch.float32)\n",
        "index = var > 0.5\n",
        "print(index)\n",
        "index = mean + var > 0.5\n",
        "print(index)\n",
        "print(mean + var)\n",
        "_, preds = torch.max(outputs, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12])\n",
            "tensor([0, 5])\n",
            "tensor([True, True])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nvar =  torch.tensor([[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,1,0.1,0.1,0.1]], dtype=torch.float32)\\nindex = var > 0.5\\nprint(index)\\nindex = mean + var > 0.5\\nprint(index)\\nprint(mean + var)\\n\\n_, preds = torch.max(outputs, 1)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1kVmdFoAjrS"
      },
      "source": [
        "y = torch.tensor([[1,0,0],[1,0,0],[1,0,0]], dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woXLvNfiBfwM"
      },
      "source": [
        "def get_device():\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "    return device\n",
        "\n",
        "def loglikelihood_loss(y, alpha, device=None):\n",
        "    if not device:\n",
        "        device = get_device()\n",
        "    y = y.to(device)\n",
        "    alpha = alpha.to(device)\n",
        "    S = torch.sum(alpha, dim=1, keepdim=True)\n",
        "    loglikelihood_err = torch.sum(\n",
        "        (y - (alpha / S)) ** 2, dim=1, keepdim=True)\n",
        "    loglikelihood_var = torch.sum(\n",
        "        alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
        "    #loglikelihood = loglikelihood_err + loglikelihood_var\n",
        "    return loglikelihood_err,loglikelihood_var\n",
        "\n",
        "def kl_divergence(alpha, num_classes, device=None):\n",
        "    if not device:\n",
        "        device = get_device()\n",
        "    beta = torch.ones([1, num_classes], dtype=torch.float32, device=device)\n",
        "    S_alpha = torch.sum(alpha, dim=1, keepdim=True)\n",
        "    S_beta = torch.sum(beta, dim=1, keepdim=True)\n",
        "    lnB = torch.lgamma(S_alpha) - \\\n",
        "        torch.sum(torch.lgamma(alpha), dim=1, keepdim=True)\n",
        "    lnB_uni = torch.sum(torch.lgamma(beta), dim=1,\n",
        "                        keepdim=True) - torch.lgamma(S_beta)\n",
        "\n",
        "    dg0 = torch.digamma(S_alpha)\n",
        "    dg1 = torch.digamma(alpha)\n",
        "\n",
        "    kl = torch.sum((alpha - beta) * (dg1 - dg0), dim=1,\n",
        "                   keepdim=True) + lnB + lnB_uni\n",
        "    return kl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkXDWFpEAwYp",
        "outputId": "20f567c5-0d64-415d-d50a-e7283a6be3a0"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "y = torch.tensor([[1,0,-1],[0,1,0],[0,0,1]]*3, dtype=torch.float32)\n",
        "print(F.softmax(y,dim=1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.6652, 0.2447, 0.0900],\n",
            "        [0.2119, 0.5761, 0.2119],\n",
            "        [0.2119, 0.2119, 0.5761],\n",
            "        [0.6652, 0.2447, 0.0900],\n",
            "        [0.2119, 0.5761, 0.2119],\n",
            "        [0.2119, 0.2119, 0.5761],\n",
            "        [0.6652, 0.2447, 0.0900],\n",
            "        [0.2119, 0.5761, 0.2119],\n",
            "        [0.2119, 0.2119, 0.5761]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqOWB94hkEV5",
        "outputId": "3a8c5572-5f82-4937-8526-3f7ed437c21b"
      },
      "source": [
        "y2 = torch.tensor([1,2,3,4,5,6,7,8,9]).reshape(9,1)\n",
        "print(y*y2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 2., 0.],\n",
            "        [0., 0., 3.],\n",
            "        [4., 0., 0.],\n",
            "        [0., 5., 0.],\n",
            "        [0., 0., 6.],\n",
            "        [7., 0., 0.],\n",
            "        [0., 8., 0.],\n",
            "        [0., 0., 9.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2mltul3BgTu"
      },
      "source": [
        "temp = [[3,1,1], # ideal\n",
        "        [1,2,1], # ideal\n",
        "        [1,1,3], # ideal\n",
        "        [10,8,1], # practial\n",
        "        [8,10,1], # practical \n",
        "        [1,2,3], # practical\n",
        "        [1,4,1], # wrong \n",
        "        [3,1,1], # wrong \n",
        "        [1,2,1]  # wrong \n",
        "        ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZp2upKPEI9B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "89ef4b7e-6955-416d-9db8-905462f6fdd0"
      },
      "source": [
        "alpha = torch.tensor(temp, dtype=torch.float32)\n",
        "#A_err,A_var = loglikelihood_loss(y, alpha)\n",
        "kl_alpha = (alpha - 1) * (1 - y) + 1\n",
        "kl_div = kl_divergence(kl_alpha, 3)\n",
        "#loss = torch.mean(A+kl_div)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-f95da6c674a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mA_err\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mA_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloglikelihood_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mkl_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkl_div\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#loss = torch.mean(A+kl_div)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3ecca3a6c9cb>\u001b[0m in \u001b[0;36mloglikelihood_loss\u001b[0;34m(y, alpha, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     loglikelihood_err = torch.sum(\n\u001b[0;32m---> 13\u001b[0;31m         (y - (alpha / S)) ** 2, dim=1, keepdim=True)\n\u001b[0m\u001b[1;32m     14\u001b[0m     loglikelihood_var = torch.sum(\n\u001b[1;32m     15\u001b[0m         alpha * (S - alpha) / (S * S * (S + 1)), dim=1, keepdim=True)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (9) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyj1VYgsE0d0",
        "outputId": "ceaa1952-5461-49de-c22d-b9bf315fe83b"
      },
      "source": [
        "print(A_err)\n",
        "print(kl_div)\n",
        "print(kl_div+A_err)\n",
        "print(torch.mean(A_err+kl_div))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2400],\n",
            "        [0.3750],\n",
            "        [0.2400],\n",
            "        [0.3889],\n",
            "        [0.2857],\n",
            "        [0.3889],\n",
            "        [1.1667],\n",
            "        [1.0400],\n",
            "        [0.8750]])\n",
            "tensor([[0.0000],\n",
            "        [0.0000],\n",
            "        [0.0000],\n",
            "        [0.2653],\n",
            "        [0.2653],\n",
            "        [0.2653],\n",
            "        [0.9526],\n",
            "        [0.6251],\n",
            "        [0.2653]])\n",
            "tensor([[0.2400],\n",
            "        [0.3750],\n",
            "        [0.2400],\n",
            "        [0.6542],\n",
            "        [0.5510],\n",
            "        [0.6542],\n",
            "        [2.1193],\n",
            "        [1.6651],\n",
            "        [1.1403]])\n",
            "tensor(0.8488)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iukn8zjtFYVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4646f165-560c-4bac-a206-677402f4a638"
      },
      "source": [
        "y = torch.tensor([[1.0,2.0],[2.0,0.5],[0.2,3]], dtype=torch.float32)\n",
        "label = torch.tensor([1,0,0])\n",
        "_,p = torch.max(y,1)\n",
        "print(torch.where(label==p,1,-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1,  1, -1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7i_OM9LWSuc",
        "outputId": "38df0575-b9f0-4f5f-c08e-e6e5bf54ff45"
      },
      "source": [
        "y[:,-1].reshape(3,1).size()\n",
        "#print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4iy64yAZQBM",
        "outputId": "1eb402a5-c123-4cdc-97c2-c6ab07a30d18"
      },
      "source": [
        "y[:,:-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000],\n",
              "        [2.0000],\n",
              "        [0.2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}